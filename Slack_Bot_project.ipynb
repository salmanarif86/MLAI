{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Slack Bot project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmanarif86/MLAI/blob/master/Slack_Bot_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7tONKA7t2K0",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement:**\n",
        "\n",
        "I need a way to more quickly understand what's happening in the Kaggle forums and act on it. I want a faster way to summerize trends on forums posts, figure out what questions are good for me to answer and alert my teammates if the community is reporting something en masse.\n",
        "\n",
        "This is actually three seperate problems:\n",
        "\n",
        "Summerization (level of activicty, new/emerging topics, topics that are newly popular)\n",
        "Flag questions I'm likely to know the answer to\n",
        "Identify possible answerers for a given question\n",
        "Alerts based on anomaly detection (lots of community discussion around a specific topic)\n",
        "\n",
        "**Measuring success:**\n",
        "\n",
        "*Summerization:*\n",
        "\n",
        "       * User feedback on bot output (online learning)\n",
        "       * Usupervised NLU\n",
        "       \n",
        "              * Manual verification of topics\n",
        "              * Manual verification of keywords\n",
        "              \n",
        "       *Flagging questions:\n",
        "       \n",
        "              * Accuracy of predicting questions I replied using my forum history\n",
        "              \n",
        "       *Alerts\n",
        "          \n",
        "              * Accuracy of past event/bugs\n",
        "\n",
        "*Possible approches to summerization:*\n",
        "\n",
        "  **Level of activicty**\n",
        "  \n",
        "        * time series modelling of # of posts over time\n",
        "        * X posts this week (+- from last week), most popular (upvotes), most replied to\n",
        "        \n",
        "** Keywords**\n",
        "\n",
        "      * https://repositorio.inesctec.pt/bitstream/123456789/7623/1/P-00N-NF5.pdf\n",
        "      * Faster\n",
        "\n",
        "**Topics**\n",
        "\n",
        "    * More flexible to differences in vocabulary\n",
        "    \n",
        "**Hybrid Approach**\n",
        "\n",
        "  * Keywords + embeddings to group similar keywords\n",
        "  \n",
        "**Clustering based on embeddings**\n",
        "\n",
        "  * Do we want to train our own embeddings?\n",
        "  * Look into current approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMqTzszyenmg",
        "colab_type": "text"
      },
      "source": [
        "**Notes**\n",
        "\n",
        "\n",
        "**Unsupervised text Clustering**\n",
        "\n",
        "*Words - > Inputs*\n",
        "\n",
        "* Embeddings (might not be helpful if we dont train new embeddings for each time we run the model)\n",
        "\n",
        "    * Fasttext can handle out of vocabulary words\n",
        "    * Subword embeddings\n",
        "    * Biggest factor - How long do they take to train?\n",
        "    * Universal Sentence Encoder Embedding - We train our own embedding each time\n",
        "\n",
        "* Td-idf\n",
        "\n",
        "* LDA\n",
        "\n",
        "* Take the frequency matrix, remove the expected frequency (by subtracting, or using the column marginal as a noise model) -Leland McInnes\n",
        "\n",
        "* Embedding weighted with tf-idf\n",
        "\n",
        "* Embedding and then performing PCA, removing first principal component - Arora (2018) - 'A simple but tough to beat baseline sentence embeddings'\n",
        "\n",
        "* pLSA (Cheaper version of LDA)\n",
        "\n",
        "\n",
        "*Topic Modelling*\n",
        "\n",
        "* LDA\n",
        "        \n",
        "        *Too slow for this particular use case\n",
        "        *Hard to interpret\n",
        "        \n",
        "\n",
        "*Clustering with Embeddings*\n",
        "\n",
        "* Hierach. Clustering\n",
        "* Brown Clusters\n",
        "\n",
        "        * Hierachical\n",
        "        * work on the word level\n",
        "        * can be updated actively\n",
        "        * would need to find a python code\n",
        "        \n",
        "* DBSCAN\n",
        "\n",
        "      * needs embedding as input\n",
        "      * should reduce dimensionality\n",
        "      * note: clusters should be of similar density\n",
        "      * HDSCAN is the hierachical version\n",
        "\n",
        "--------------------------------------------------------\n",
        "\n",
        "\n",
        "Whole pipeline : \n",
        "\n",
        "* https://topsmb.github.io\n",
        "* https://github.com/bigartm/bigartm\n",
        "\n",
        "1. Words to  numbers\n",
        "\n",
        "* tf-idf\n",
        "* LDA\n",
        "* pLSA\n",
        "* Embeddings\n",
        "\n",
        "    * fasttext\n",
        "    * USE (universal sentence encoder embeddings ) Embeddings\n",
        "    * GloVe?\n",
        "    * Word2Vec\n",
        "    * ELMo Embeddings\n",
        "    * text to knowledge mapping - mapping text to knowledge using Multi-Sense LSTMs - wont probably do as this would require building our own knoeldge graph -   no bandwith\n",
        "\n",
        "2. Dimensionality Reduction\n",
        "  \n",
        "    * UMAP\n",
        "    * PCA\n",
        "    \n",
        "3. Clustering\n",
        "\n",
        "    * DBSCAN\n",
        "    * HDBSCAN\n",
        "    * Specteral Clusterings\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmRadv4XehhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "***Notes******"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}