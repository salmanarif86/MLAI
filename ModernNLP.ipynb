{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModernNLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmanarif86/MLAI/blob/master/ModernNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp5XVHCUmOB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VRuxhltmRwM",
        "colab_type": "text"
      },
      "source": [
        "#spaCy — Industrial-Strength NLP in Python\n",
        "![alt text](https://camo.githubusercontent.com/5544cd4d424dafdd00f9c3064157cc86b4a892cc/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f736b69706772616d2d696d616765732f73706143792e706e67)\n",
        "spaCy is an industrial-strength natural language processing (NLP) library for Python. spaCy's goal is to take recent advancements in natural language processing out of research papers and put them in the hands of users to build production software.\n",
        "\n",
        "spaCy handles many tasks commonly associated with building an end-to-end natural language processing pipeline:\n",
        "\n",
        "1. Tokenization\n",
        "2. Text normalization, such as lowercasing, stemming/lemmatization\n",
        "3. Part-of-speech tagging\n",
        "4. Syntactic dependency parsing\n",
        "5. Sentence boundary detection\n",
        "6. Named entity recognition and annotation\n",
        "\n",
        "In the \"batteries included\" Python tradition, spaCy contains built-in data and models which you can use out-of-the-box for processing general-purpose English language text:\n",
        "\n",
        "1. Large English vocabulary, including stopword lists\n",
        "2. Token \"probabilities\"\n",
        "3. Word vectors\n",
        "\n",
        "spaCy is written in optimized Cython, which means it's fast. According to a few independent sources, it's the fastest syntactic parser available in any language. Key pieces of the spaCy parsing pipeline are written in pure C, enabling efficient multithreading (i.e., spaCy can release the GIL)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWdC1TlfmtqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from spacy import displacy\n",
        "import spacy.cli\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP8QcRJqegU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "65ccf7d8-4ba8-4ca1-940a-e9bddf35f38f"
      },
      "source": [
        "spacy.cli.download('en_core_web_lg')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWhWr9r4fZ5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqBeDjn5r1Lp",
        "colab_type": "text"
      },
      "source": [
        "##Context\n",
        "\n",
        "I was always fascinated by the food culture of Bengaluru. Restaurants from all over the world can be found here in Bengaluru. From United States to Japan, Russia to Antarctica, you get all type of cuisines here. Delivery, Dine-out, Pubs, Bars, Drinks,Buffet, Desserts you name it and Bengaluru has it. Bengaluru is best place for foodies. The number of restaurant are increasing day by day. Currently which stands at approximately 12,000 restaurants. With such an high number of restaurants. This industry hasn't been saturated yet. And new restaurants are opening every day. However it has become difficult for them to compete with already established restaurants. The key issues that continue to pose a challenge to them include high real estate costs, rising food costs, shortage of quality manpower, fragmented supply chain and over-licensing. This Zomato data aims at analysing demography of the location. Most importantly it will help new restaurants in deciding their theme, menus, cuisine, cost etc for a particular location. It also aims at finding similarity between neighborhoods of Bengaluru on the basis of food. The dataset also contains reviews for each of the restaurant which will help in finding overall rating for the place.\n",
        "\n",
        "We will demonstrate the power of Modern NLP on this dataset\n",
        "\n",
        "##Content\n",
        "\n",
        "The data is accurate to that available on the zomato website until 15 March 2019. This data is also available on Kaggle. We will create a dataframe and check a few attributes and do some EDA. The column we are most intersted in review_list. The column is a list of tuples containing reviews for the restaurant, each tuple consists of two values, rating and review by the customer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehnxHUyoWeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('zomato.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5FUbhtht0Qu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ace5648a-1881-4207-8b91-2006f2bdd4bf"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>address</th>\n",
              "      <th>name</th>\n",
              "      <th>online_order</th>\n",
              "      <th>book_table</th>\n",
              "      <th>rate</th>\n",
              "      <th>votes</th>\n",
              "      <th>phone</th>\n",
              "      <th>location</th>\n",
              "      <th>rest_type</th>\n",
              "      <th>dish_liked</th>\n",
              "      <th>cuisines</th>\n",
              "      <th>approx_cost(for two people)</th>\n",
              "      <th>reviews_list</th>\n",
              "      <th>menu_item</th>\n",
              "      <th>listed_in(type)</th>\n",
              "      <th>listed_in(city)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
              "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
              "      <td>Jalsa</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4.1/5</td>\n",
              "      <td>775</td>\n",
              "      <td>080 42297555\\r\\n+91 9743772233</td>\n",
              "      <td>Banashankari</td>\n",
              "      <td>Casual Dining</td>\n",
              "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
              "      <td>North Indian, Mughlai, Chinese</td>\n",
              "      <td>800</td>\n",
              "      <td>[('Rated 4.0', 'RATED\\n  A beautiful place to ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Buffet</td>\n",
              "      <td>Banashankari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
              "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
              "      <td>Spice Elephant</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>4.1/5</td>\n",
              "      <td>787</td>\n",
              "      <td>080 41714161</td>\n",
              "      <td>Banashankari</td>\n",
              "      <td>Casual Dining</td>\n",
              "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
              "      <td>Chinese, North Indian, Thai</td>\n",
              "      <td>800</td>\n",
              "      <td>[('Rated 4.0', 'RATED\\n  Had been here for din...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Buffet</td>\n",
              "      <td>Banashankari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
              "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
              "      <td>San Churro Cafe</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>3.8/5</td>\n",
              "      <td>918</td>\n",
              "      <td>+91 9663487993</td>\n",
              "      <td>Banashankari</td>\n",
              "      <td>Cafe, Casual Dining</td>\n",
              "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
              "      <td>Cafe, Mexican, Italian</td>\n",
              "      <td>800</td>\n",
              "      <td>[('Rated 3.0', \"RATED\\n  Ambience is not that ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Buffet</td>\n",
              "      <td>Banashankari</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ... listed_in(city)\n",
              "0  https://www.zomato.com/bangalore/jalsa-banasha...  ...    Banashankari\n",
              "1  https://www.zomato.com/bangalore/spice-elephan...  ...    Banashankari\n",
              "2  https://www.zomato.com/SanchurroBangalore?cont...  ...    Banashankari\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KkFrSii8zyl",
        "colab_type": "text"
      },
      "source": [
        "Converting string representation of list into lits using literal_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZhgRvYowO-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reviews_list = df.reviews_list.apply(lambda x: ast.literal_eval(x))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yll8uNOkMWil",
        "colab_type": "text"
      },
      "source": [
        "Coverting string of tuples into a dataframe by first setting the column 'name' as index and then selecting the review_list column and then applying pd.series to seperate elements of list and then stacking them vertically and then applying pd.series to seprate element of tuples and adding 'val_' as a prefix to the new column and then reseting index to move the column 'name' back to the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOpW2GRbw5-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reviews=df.set_index('name').reviews_list.apply(pd.Series).stack().apply(pd.Series).add_prefix('val_').reset_index().drop('level_1', axis=1)\n",
        "  \n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdxWpfkvOgwE",
        "colab_type": "text"
      },
      "source": [
        "Saving a copy of the file with all reviews unpacked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbH_-PwhxB1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reviews.to_csv('banglore_reviews.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOi2Nfiw-k_r",
        "colab_type": "text"
      },
      "source": [
        "There are alot of non-ascii gibrish data that needs to be cleaned. The following function removes all non-ascii text and replaces it with blank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgTauSatncrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def replace_foreign_characters(s):\n",
        "    return re.sub(r'[^\\x00-\\x7f]',r'', s)\n",
        "\n",
        "df_reviews.val_1 = df_reviews.val_1.apply(lambda x: replace_foreign_characters(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0n2Txd-43F",
        "colab_type": "text"
      },
      "source": [
        "Let's extract the largest comment in our data and perform some modern NLP on it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdIgMdXjXELj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66213606-7c1a-438e-babc-9c72a740b3d9"
      },
      "source": [
        "np.argmax(np.array(df_reviews.val_1.apply(lambda x : len(x))))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc-UPxHOXiA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_review= df_reviews.iloc[68248]['val_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHw-awJ9W6Gb",
        "colab_type": "text"
      },
      "source": [
        "Here is a snapshot of what the comment looks like. The customer as you can see really loves the ambiance and the diffrent variety of food. We will use this sample review to show some out-of-the box capabilities that SpaCy has and then do more in-depth modelling. Looks like not much has changed but all the processing has been done under the hood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIDB5imgpt2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "7445c756-8731-4550-a87d-bed5810f3401"
      },
      "source": [
        "%%time\n",
        "\n",
        "parsed_review = nlp(sample_review)\n",
        "print(parsed_review)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RATED\n",
            "  I visited the place recently on its opening night. Truly amazed by the decor of the place. They have indoor as well as outdoor sitting area. Decorated with sparkling lights, the place was definitely giving a Christmas vibes.\n",
            "\n",
            "Coming to the food and drinks, I tried food from the ala carte menu. Chef Swatantra and his team has done a fabulous job with the food.\n",
            "\n",
            "The chakhna or better known as scotch nuts were my favourite. These babies were completely addictive. The best dish to much along with the cocktails.\n",
            "\n",
            "We also tried the Mojito chicken pizza, the marinated chicken with olives is quite a filler.\n",
            "\n",
            "In prawns we tried the Teppanyaki wasabi prawns, recommended by the chef himself and it was definitely worth mentioning here. You cannot miss this one. The light zing of the wasabi completely brightened the dish.\n",
            "\n",
            "Patrani Machhi is another dish which liked a lot. Traditionally made in Parsi households, was presented in different way, they served it with Hyderabadi thiccha.\n",
            "\n",
            "\n",
            "\n",
            "priyankafoodfuntravel.wordpress.com\n",
            "CPU times: user 51.8 ms, sys: 3 ms, total: 54.8 ms\n",
            "Wall time: 135 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lySBg_aUWT7X",
        "colab_type": "text"
      },
      "source": [
        "So all the processing has already happened and what we are doing below is just examining what SpaCy has evaluated. We are going to step through various functionalities that SpaCy offers.Let's investigate the parsed review object now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4nQx20Xvd9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1126
        },
        "outputId": "b6e1d4bb-6bab-49fb-bbf8-cd82a48f56c9"
      },
      "source": [
        "for num, sentence in enumerate(parsed_review.sents):\n",
        "  print ('Sentence {}:'.format(num + 1))\n",
        "  print (sentence)\n",
        "  print ('')\n",
        "  \n",
        "\n",
        "  \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 1:\n",
            "RATED\n",
            "  \n",
            "\n",
            "Sentence 2:\n",
            "I visited the place recently on its opening night.\n",
            "\n",
            "Sentence 3:\n",
            "Truly amazed by the decor of the place.\n",
            "\n",
            "Sentence 4:\n",
            "They have indoor as well as outdoor sitting area.\n",
            "\n",
            "Sentence 5:\n",
            "Decorated with sparkling lights, the place was definitely giving a Christmas vibes.\n",
            "\n",
            "\n",
            "\n",
            "Sentence 6:\n",
            "Coming to the food and drinks, I tried food from the ala carte menu.\n",
            "\n",
            "Sentence 7:\n",
            "Chef Swatantra and his team has done a fabulous job with the food.\n",
            "\n",
            "\n",
            "\n",
            "Sentence 8:\n",
            "The chakhna or better known as scotch nuts were my favourite.\n",
            "\n",
            "Sentence 9:\n",
            "These babies were completely addictive.\n",
            "\n",
            "Sentence 10:\n",
            "The best dish to much along with the cocktails.\n",
            "\n",
            "\n",
            "\n",
            "Sentence 11:\n",
            "We also tried the Mojito chicken pizza, the marinated chicken with olives is quite a filler.\n",
            "\n",
            "\n",
            "\n",
            "Sentence 12:\n",
            "In prawns we tried the Teppanyaki wasabi prawns, recommended by the chef himself and it was definitely worth mentioning here.\n",
            "\n",
            "Sentence 13:\n",
            "You cannot miss this one.\n",
            "\n",
            "Sentence 14:\n",
            "The light zing of the wasabi completely brightened the dish.\n",
            "\n",
            "\n",
            "\n",
            "Sentence 15:\n",
            "Patrani Machhi is another dish which liked a lot.\n",
            "\n",
            "Sentence 16:\n",
            "Traditionally made in Parsi households, was presented in different way, they served it with Hyderabadi thiccha.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sentence 17:\n",
            "priyankafoodfuntravel.wordpress.com\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59x_LymiBG61",
        "colab_type": "text"
      },
      "source": [
        "What about named entity detection?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMT28C3QAsuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "e597767f-11fd-4df3-8590-16f40c892ad0"
      },
      "source": [
        "for num, entity in enumerate(parsed_review.ents):\n",
        "  print('Entity {}:'.format(num + 1), entity, '-',entity.label_)\n",
        "  print('')\n",
        "\n",
        "  \n",
        "displacy.render(parsed_review, style='ent', jupyter=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entity 1: opening night - TIME\n",
            "\n",
            "Entity 2: Christmas - DATE\n",
            "\n",
            "Entity 3: Chef Swatantra - PERSON\n",
            "\n",
            "Entity 4: Mojito - PRODUCT\n",
            "\n",
            "Entity 5: Teppanyaki - NORP\n",
            "\n",
            "Entity 6: Parsi - NORP\n",
            "\n",
            "Entity 7: Hyderabadi - NORP\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">RATED</br>  I visited the place recently on its \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    opening night\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              ". Truly amazed by the decor of the place. They have indoor as well as outdoor sitting area. Decorated with sparkling lights, the place was definitely giving a \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Christmas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " vibes.</br></br>Coming to the food and drinks, I tried food from the ala carte menu. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Chef Swatantra\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and his team has done a fabulous job with the food.</br></br>The chakhna or better known as scotch nuts were my favourite. These babies were completely addictive. The best dish to much along with the cocktails.</br></br>We also tried the \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Mojito\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " chicken pizza, the marinated chicken with olives is quite a filler.</br></br>In prawns we tried the \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Teppanyaki\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " wasabi prawns, recommended by the chef himself and it was definitely worth mentioning here. You cannot miss this one. The light zing of the wasabi completely brightened the dish.</br></br>Patrani Machhi is another dish which liked a lot. Traditionally made in \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Parsi\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " households, was presented in different way, they served it with \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Hyderabadi\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " thiccha.\n",
              "\n",
              "\n",
              "\n",
              "priyankafoodfuntravel.wordpress.com</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PkxDznvMPc3",
        "colab_type": "text"
      },
      "source": [
        "What about part of speech tagging?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj05pU-yCC_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "4c72ddff-d712-4c96-e695-e81aef673244"
      },
      "source": [
        "token_text = [token.orth_ for token in parsed_review]\n",
        "token_pos = [token.pos_ for token in parsed_review]\n",
        "\n",
        "pd.DataFrame(zip(token_text, token_pos),\n",
        "             columns=['token_text', 'part_of_speech']).head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_text</th>\n",
              "      <th>part_of_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RATED</td>\n",
              "      <td>PROPN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n</td>\n",
              "      <td>SPACE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visited</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the</td>\n",
              "      <td>DET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>place</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recently</td>\n",
              "      <td>ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on</td>\n",
              "      <td>ADP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>its</td>\n",
              "      <td>DET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>opening</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  token_text part_of_speech\n",
              "0      RATED          PROPN\n",
              "1       \\n            SPACE\n",
              "2          I           PRON\n",
              "3    visited           VERB\n",
              "4        the            DET\n",
              "5      place           NOUN\n",
              "6   recently            ADV\n",
              "7         on            ADP\n",
              "8        its            DET\n",
              "9    opening           NOUN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvP76ftXMkQQ",
        "colab_type": "text"
      },
      "source": [
        "What about text normalization, like stemming/lemmatization and shape analysis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egi687b-MjQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "e875456d-f295-4afb-b0e6-688c375555b5"
      },
      "source": [
        "token_lemma = [token.lemma_ for token in parsed_review]\n",
        "token_shape = [token.shape_ for token in parsed_review]\n",
        "\n",
        "pd.DataFrame(zip(token_text, token_lemma, token_shape),\n",
        "             columns=['token_text', 'token_lemma', 'token_shape']).head(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_text</th>\n",
              "      <th>token_lemma</th>\n",
              "      <th>token_shape</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RATED</td>\n",
              "      <td>RATED</td>\n",
              "      <td>XXXX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I</td>\n",
              "      <td>-PRON-</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visited</td>\n",
              "      <td>visit</td>\n",
              "      <td>xxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>xxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>place</td>\n",
              "      <td>place</td>\n",
              "      <td>xxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recently</td>\n",
              "      <td>recently</td>\n",
              "      <td>xxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "      <td>xx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>its</td>\n",
              "      <td>-PRON-</td>\n",
              "      <td>xxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>opening</td>\n",
              "      <td>opening</td>\n",
              "      <td>xxxx</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  token_text token_lemma token_shape\n",
              "0      RATED       RATED        XXXX\n",
              "1       \\n          \\n          \\n  \n",
              "2          I      -PRON-           X\n",
              "3    visited       visit        xxxx\n",
              "4        the         the         xxx\n",
              "5      place       place        xxxx\n",
              "6   recently    recently        xxxx\n",
              "7         on          on          xx\n",
              "8        its      -PRON-         xxx\n",
              "9    opening     opening        xxxx"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E2RhDKtM8aN",
        "colab_type": "text"
      },
      "source": [
        "What about token-level entity analysis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7YJqCTuMXVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1882
        },
        "outputId": "5662560f-d766-40f3-8502-aaab21e0ec38"
      },
      "source": [
        "\n",
        "token_entity_type = [token.ent_type_ for token in parsed_review]\n",
        "token_entity_iob = [token.ent_iob_ for token in parsed_review]\n",
        "\n",
        "pd.DataFrame(zip(token_text, token_entity_type, token_entity_iob),\n",
        "             columns=['token_text', 'entity_type', 'inside_outside_begin'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_text</th>\n",
              "      <th>entity_type</th>\n",
              "      <th>inside_outside_begin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RATED</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visited</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>place</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recently</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>its</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>opening</td>\n",
              "      <td>TIME</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>night</td>\n",
              "      <td>TIME</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Truly</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>amazed</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>by</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>decor</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>of</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>place</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>.</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>They</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>have</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>indoor</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>as</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>well</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>as</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>outdoor</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>sitting</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>area</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Machhi</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>is</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>another</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>dish</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>which</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>liked</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>lot</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>.</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Traditionally</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>made</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>in</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Parsi</td>\n",
              "      <td>NORP</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>households</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>was</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>presented</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>in</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>different</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>way</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>they</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>served</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>it</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>with</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Hyderabadi</td>\n",
              "      <td>NORP</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>thiccha</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>.</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>\\n\\n\\n\\n</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>priyankafoodfuntravel.wordpress.com</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              token_text entity_type inside_outside_begin\n",
              "0                                  RATED                                O\n",
              "1                                   \\n                                  O\n",
              "2                                      I                                O\n",
              "3                                visited                                O\n",
              "4                                    the                                O\n",
              "5                                  place                                O\n",
              "6                               recently                                O\n",
              "7                                     on                                O\n",
              "8                                    its                                O\n",
              "9                                opening        TIME                    B\n",
              "10                                 night        TIME                    I\n",
              "11                                     .                                O\n",
              "12                                 Truly                                O\n",
              "13                                amazed                                O\n",
              "14                                    by                                O\n",
              "15                                   the                                O\n",
              "16                                 decor                                O\n",
              "17                                    of                                O\n",
              "18                                   the                                O\n",
              "19                                 place                                O\n",
              "20                                     .                                O\n",
              "21                                  They                                O\n",
              "22                                  have                                O\n",
              "23                                indoor                                O\n",
              "24                                    as                                O\n",
              "25                                  well                                O\n",
              "26                                    as                                O\n",
              "27                               outdoor                                O\n",
              "28                               sitting                                O\n",
              "29                                  area                                O\n",
              "..                                   ...         ...                  ...\n",
              "167                               Machhi                                O\n",
              "168                                   is                                O\n",
              "169                              another                                O\n",
              "170                                 dish                                O\n",
              "171                                which                                O\n",
              "172                                liked                                O\n",
              "173                                    a                                O\n",
              "174                                  lot                                O\n",
              "175                                    .                                O\n",
              "176                        Traditionally                                O\n",
              "177                                 made                                O\n",
              "178                                   in                                O\n",
              "179                                Parsi        NORP                    B\n",
              "180                           households                                O\n",
              "181                                    ,                                O\n",
              "182                                  was                                O\n",
              "183                            presented                                O\n",
              "184                                   in                                O\n",
              "185                            different                                O\n",
              "186                                  way                                O\n",
              "187                                    ,                                O\n",
              "188                                 they                                O\n",
              "189                               served                                O\n",
              "190                                   it                                O\n",
              "191                                 with                                O\n",
              "192                           Hyderabadi        NORP                    B\n",
              "193                              thiccha                                O\n",
              "194                                    .                                O\n",
              "195                             \\n\\n\\n\\n                                O\n",
              "196  priyankafoodfuntravel.wordpress.com                                O\n",
              "\n",
              "[197 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22BleRUgNW1L",
        "colab_type": "text"
      },
      "source": [
        "What about a variety of other token-level attributes, such as the relative frequency of tokens, and whether or not a token matches any of these categories?\n",
        "\n",
        "1. stopword\n",
        "2. punctuation\n",
        "3. whitespace\n",
        "4. represents a number\n",
        "\n",
        "whether or not the token is included in spaCy's default vocabulary?\n",
        "\n",
        "It also shows the log probability of each token which has been calculated by observing a very large corpus of text. The numbers are represented as negative log and the more the number are closer to zero the more common the words are in english language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UKnCosUM_7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1882
        },
        "outputId": "53be7ee6-d1e1-4e7f-a6aa-e493c45c92b6"
      },
      "source": [
        "token_attributes = [(token.orth_, token.prob,\n",
        "                     token.is_stop,\n",
        "                     token.is_punct,\n",
        "                     token.is_space,\n",
        "                     token.like_num,\n",
        "                     token.is_oov)\n",
        "                    for token in parsed_review]\n",
        "\n",
        "df = pd.DataFrame(token_attributes,\n",
        "                  columns=['text',\n",
        "                           'log_probability',\n",
        "                           'stop?',\n",
        "                           'punctuation?',\n",
        "                           'whitespace?',\n",
        "                           'number?',\n",
        "                           'out of vocab.?'])\n",
        "\n",
        "df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?'].applymap(lambda x: u'Yes' if x else u''))\n",
        "                                               \n",
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>log_probability</th>\n",
              "      <th>stop?</th>\n",
              "      <th>punctuation?</th>\n",
              "      <th>whitespace?</th>\n",
              "      <th>number?</th>\n",
              "      <th>out of vocab.?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RATED</td>\n",
              "      <td>-16.739208</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n</td>\n",
              "      <td>-11.854727</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I</td>\n",
              "      <td>-3.791565</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>visited</td>\n",
              "      <td>-11.436536</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the</td>\n",
              "      <td>-3.528767</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>place</td>\n",
              "      <td>-7.954748</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recently</td>\n",
              "      <td>-9.260489</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>on</td>\n",
              "      <td>-5.172736</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>its</td>\n",
              "      <td>-7.321458</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>opening</td>\n",
              "      <td>-10.299832</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>night</td>\n",
              "      <td>-8.517073</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td>-3.067898</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Truly</td>\n",
              "      <td>-12.418079</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>amazed</td>\n",
              "      <td>-11.480827</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>by</td>\n",
              "      <td>-6.375087</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the</td>\n",
              "      <td>-3.528767</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>decor</td>\n",
              "      <td>-14.021763</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>of</td>\n",
              "      <td>-4.275874</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>-3.528767</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>place</td>\n",
              "      <td>-7.954748</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>.</td>\n",
              "      <td>-3.067898</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>They</td>\n",
              "      <td>-7.078901</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>have</td>\n",
              "      <td>-5.156485</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>indoor</td>\n",
              "      <td>-12.485910</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>as</td>\n",
              "      <td>-5.534485</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>well</td>\n",
              "      <td>-6.995904</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>as</td>\n",
              "      <td>-5.534485</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>outdoor</td>\n",
              "      <td>-12.159930</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>sitting</td>\n",
              "      <td>-9.618224</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>area</td>\n",
              "      <td>-8.839012</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Machhi</td>\n",
              "      <td>-20.000000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>is</td>\n",
              "      <td>-4.457749</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>another</td>\n",
              "      <td>-7.801507</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>dish</td>\n",
              "      <td>-11.522576</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>which</td>\n",
              "      <td>-6.877471</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>liked</td>\n",
              "      <td>-9.439147</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>a</td>\n",
              "      <td>-3.929788</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>lot</td>\n",
              "      <td>-7.113600</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>.</td>\n",
              "      <td>-3.067898</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Traditionally</td>\n",
              "      <td>-14.232681</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>made</td>\n",
              "      <td>-7.399899</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>in</td>\n",
              "      <td>-4.619072</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Parsi</td>\n",
              "      <td>-17.212673</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>households</td>\n",
              "      <td>-13.157230</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>,</td>\n",
              "      <td>-3.454960</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>was</td>\n",
              "      <td>-5.252320</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>presented</td>\n",
              "      <td>-11.112039</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>in</td>\n",
              "      <td>-4.619072</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>different</td>\n",
              "      <td>-7.630641</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>way</td>\n",
              "      <td>-6.736272</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>,</td>\n",
              "      <td>-3.454960</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>they</td>\n",
              "      <td>-5.524368</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>served</td>\n",
              "      <td>-11.095252</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>it</td>\n",
              "      <td>-4.388050</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>with</td>\n",
              "      <td>-5.243250</td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Hyderabadi</td>\n",
              "      <td>-18.058977</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>thiccha</td>\n",
              "      <td>-20.000000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>.</td>\n",
              "      <td>-3.067898</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>\\n\\n\\n\\n</td>\n",
              "      <td>-9.724448</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>priyankafoodfuntravel.wordpress.com</td>\n",
              "      <td>-20.000000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    text  ...  out of vocab.?\n",
              "0                                  RATED  ...                \n",
              "1                                   \\n    ...                \n",
              "2                                      I  ...                \n",
              "3                                visited  ...                \n",
              "4                                    the  ...                \n",
              "5                                  place  ...                \n",
              "6                               recently  ...                \n",
              "7                                     on  ...                \n",
              "8                                    its  ...                \n",
              "9                                opening  ...                \n",
              "10                                 night  ...                \n",
              "11                                     .  ...                \n",
              "12                                 Truly  ...                \n",
              "13                                amazed  ...                \n",
              "14                                    by  ...                \n",
              "15                                   the  ...                \n",
              "16                                 decor  ...                \n",
              "17                                    of  ...                \n",
              "18                                   the  ...                \n",
              "19                                 place  ...                \n",
              "20                                     .  ...                \n",
              "21                                  They  ...                \n",
              "22                                  have  ...                \n",
              "23                                indoor  ...                \n",
              "24                                    as  ...                \n",
              "25                                  well  ...                \n",
              "26                                    as  ...                \n",
              "27                               outdoor  ...                \n",
              "28                               sitting  ...                \n",
              "29                                  area  ...                \n",
              "..                                   ...  ...             ...\n",
              "167                               Machhi  ...             Yes\n",
              "168                                   is  ...                \n",
              "169                              another  ...                \n",
              "170                                 dish  ...                \n",
              "171                                which  ...                \n",
              "172                                liked  ...                \n",
              "173                                    a  ...                \n",
              "174                                  lot  ...                \n",
              "175                                    .  ...                \n",
              "176                        Traditionally  ...                \n",
              "177                                 made  ...                \n",
              "178                                   in  ...                \n",
              "179                                Parsi  ...                \n",
              "180                           households  ...                \n",
              "181                                    ,  ...                \n",
              "182                                  was  ...                \n",
              "183                            presented  ...                \n",
              "184                                   in  ...                \n",
              "185                            different  ...                \n",
              "186                                  way  ...                \n",
              "187                                    ,  ...                \n",
              "188                                 they  ...                \n",
              "189                               served  ...                \n",
              "190                                   it  ...                \n",
              "191                                 with  ...                \n",
              "192                           Hyderabadi  ...                \n",
              "193                              thiccha  ...             Yes\n",
              "194                                    .  ...                \n",
              "195                             \\n\\n\\n\\n  ...                \n",
              "196  priyankafoodfuntravel.wordpress.com  ...             Yes\n",
              "\n",
              "[197 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nmnq66hjbPv",
        "colab_type": "text"
      },
      "source": [
        "Now lets just inspect the out of vocabulary words. As you  might have seen previously we loaded the large corpus and are thus comparing against it. Pretty good!!! The only words it was not able to detect are very local indian food items. It was also able to detect the word 'parsi' & 'Hyderabadi'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMoZpyn5jv1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "611c7d8c-f28c-48e0-b6a5-5ba5db0ae3a0"
      },
      "source": [
        "df[df['out of vocab.?']=='Yes']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>log_probability</th>\n",
              "      <th>stop?</th>\n",
              "      <th>punctuation?</th>\n",
              "      <th>whitespace?</th>\n",
              "      <th>number?</th>\n",
              "      <th>out of vocab.?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Swatantra</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>chakhna</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>Patrani</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Machhi</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>thiccha</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>priyankafoodfuntravel.wordpress.com</td>\n",
              "      <td>-20.0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    text  ...  out of vocab.?\n",
              "63                             Swatantra  ...             Yes\n",
              "78                               chakhna  ...             Yes\n",
              "166                              Patrani  ...             Yes\n",
              "167                               Machhi  ...             Yes\n",
              "193                              thiccha  ...             Yes\n",
              "196  priyankafoodfuntravel.wordpress.com  ...             Yes\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlIxs0rPPGJB",
        "colab_type": "text"
      },
      "source": [
        "If the text you'd like to process is general-purpose English language text (i.e., not domain-specific, like medical literature), spaCy is ready to use out-of-the-box.\n",
        "\n",
        "I think it will eventually become a core part of the Python data science ecosystem — it will do for natural language computing what other great libraries have done for numerical computing.\n",
        "\n",
        "Phrase Modeling\n",
        "Phrase modeling is another approach to learning combinations of tokens that together represent meaningful multi-word concepts. We can develop phrase models by looping over the the words in our reviews and looking for words that co-occur (i.e., appear one after another) together much more frequently than you would expect them to by random chance. The formula our phrase models will use to determine whether two tokens $A$ and $B$ constitute a phrase is:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ">>>>>>>![alt text](https://render.githubusercontent.com/render/math?math=%5Cfrac%7Bcount%28A%5C%20B%29%20-%20count_%7Bmin%7D%7D%7Bcount%28A%29%20%2A%20count%28B%29%7D%20%2A%20N%20%26gt%3B%20threshold&mode=display)\n",
        "\n",
        "\n",
        "...where:\n",
        "\n",
        "1. $count(A)$ is the number of times token $A$ appears in the corpus\n",
        "2. $count(B)$ is the number of times token $B$ appears in the corpus\n",
        "3. $count(A\\ B)$ is the number of times the tokens $A\\ B$ appear in the corpus in order\n",
        "4. $N$ is the total size of the corpus vocabulary\n",
        "5. $count_{min}$ is a user-defined parameter to ensure that accepted phrases occur a minimum number of times\n",
        "6. $threshold$ is a user-defined parameter to control how strong of a relationship between two tokens the model requires before accepting them as a phrase\n",
        "\n",
        "Once our phrase model has been trained on our corpus, we can apply it to new text. When our model encounters two tokens in new text that identifies as a phrase, it will merge the two into a single new token.\n",
        "\n",
        "Phrase modeling is superficially similar to named entity detection in that you would expect named entities to become phrases in the model (so new york would become new_york). But you would also expect multi-word expressions that represent common concepts, but aren't specifically named entities (such as happy hour) to also become phrases in the model.\n",
        "\n",
        "We turn to the indispensible gensim library to help us with phrase modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHAH9iYYNg6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Phrases\n",
        "from gensim.models.word2vec import LineSentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nSkXzCYQl89",
        "colab_type": "text"
      },
      "source": [
        "As we're performing phrase modeling, we'll be doing some iterative data transformation at the same time. Our roadmap for data preparation includes:\n",
        "\n",
        "1. Segment text of complete reviews into sentences & normalize text\n",
        "2. First-order phrase modeling $\\rightarrow$ apply first-order phrase model to transform sentences\n",
        "3. Second-order phrase modeling $\\rightarrow$ apply second-order phrase model to transform sentences\n",
        "4. Apply text normalization and second-order phrase model to text of complete reviews\n",
        "\n",
        "We'll use this transformed data as the input for some higher-level modeling approaches in the following sections.\n",
        "\n",
        "First, let's define a few helper functions that we'll use for text normalization. In particular, the lemmatized_sentence_corpus generator function will use spaCy to:\n",
        "\n",
        "1. Iterate over the 1M reviews \n",
        "2. Segment the reviews into individual sentences\n",
        "3. Remove punctuation and excess whitespace\n",
        "\n",
        "Lemmatize the text\n",
        "... and do so efficiently in parallel, thanks to spaCy's nlp.pipe() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u54saRJvQS6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}